# Процес аналізу датасету

Опис того, як `analyze.py` незалежно аналізує згенерований датасет діалогів.

## Загальна ідея

Аналізатор бере готовий датасет (`data/dataset.json`) і проганяє кожен діалог через LLM,
щоб отримати незалежну оцінку якості. Результати не копіюються з метаданих генератора —
LLM дивиться на діалог "з нуля". Це дозволяє порівняти, наскільки точно
аналізатор розпізнає інтенти, задоволеність і помилки агента.

## Кроки

### 1. Завантаження датасету

Читається `data/dataset.json`. Якщо файл не існує — аналізатор зупиняється
з повідомленням запустити `generate.py` спочатку.

### 2. Аналіз через LLM

`DatasetAnalyzer.analyze_batch()` обробляє діалоги батчами (за замовчуванням по 5).

Для кожного батчу формується один промпт (`build_batch_dialog_prompt`),
і LLM повертає JSON-масив з аналізом кожного діалогу. Якщо батчевий запит падає —
діалоги аналізуються по одному як fallback.

Для кожного діалогу LLM визначає 9 метрик:

| Метрика | Значення | Опис |
|---------|----------|------|
| `intent` | одне з `VALID_INTENTS` | Основний намір клієнта |
| `satisfaction` | `satisfied` / `neutral` / `unsatisfied` | Реальна задоволеність клієнта |
| `quality_score` | 1–5 | Оцінка роботи агента (коригується на основі помилок і resolution) |
| `agent_mistakes` | список з `AGENT_MISTAKES` | Конкретні помилки агента |
| `hidden_dissatisfaction` | `true` / `false` | Клієнт ввічливий, але проблема не вирішена |
| `tone_agent` | `professional` / `casual` / `rude` | Тон агента |
| `tone_client` | `calm` / `frustrated` / `angry` | Тон клієнта |
| `resolution` | `resolved` / `partially_resolved` / `unresolved` | Статус вирішення |
| `resolution_summary` | текст | Короткий опис того, що сталося |

### Валідація результатів

`_validate_analysis()` нормалізує відповідь LLM:

- **intent** — fuzzy-matching проти `VALID_INTENTS` (якщо не знайдено — `other`)
- **quality_score** — обрізається до діапазону 1–5 і коригується:
  мінус 1 за кожну помилку агента, плюс 1 якщо resolved, мінус 1 якщо unresolved
- **enum-поля** — перевіряються на допустимі значення, невалідні замінюються на default
- **agent_mistakes** — фільтруються, залишаються тільки ті, що є в `AGENT_MISTAKES`

### 3. Збереження і статистика

Результат зберігається в `data/analysis.json`. Кожен запис містить:
- `id` — ідентифікатор діалогу
- `dialog` — сам діалог
- `analysis` — незалежний аналіз від LLM
- `generator_metadata` — оригінальні метадані генератора (якщо є, для порівняння)

Агреговані статистики зберігаються в `data/analysis_stats.json`:
розподіл за інтентами, satisfaction, тонами, помилками, середній quality_score.

### Порівняння з генератором

Якщо в датасеті є `metadata` від генератора, аналізатор порівнює свої результати
з оригінальними мітками і виводить точність для:
- intent match
- satisfaction match
- hidden dissatisfaction match

## Конфігурація та налаштування

Процес аналізу можна кастомізувати через:
- `src/config/constants.py`: зміна списку `VALID_INTENTS` або `AGENT_MISTAKES` вплине на валідацію.
- `src/analyzer/main.py`: параметр `batch_size` (за замовчуванням 5) дозволяє регулювати навантаження на LLM.

### Робота в Docker
Якщо ви запускаєте аналіз у Docker-контейнері, переконайтеся, що `OLLAMA_HOST` вказано правильно (за замовчуванням у `docker-compose.yml` це `http://ollama:11434`).

